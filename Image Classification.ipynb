{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOh/dYDcb3x/cl5Q46+Knk8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirams1983/pyimagesearch-python-machine-learning/blob/master/Image%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ALt1_pJNd1D",
        "outputId": "1274c614-aaa2-4492-e4eb-4866e69725ef"
      },
      "source": [
        "!git clone https://github.com/srirams1983/pyimagesearch-python-machine-learning.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pyimagesearch-python-machine-learning'...\n",
            "remote: Enumerating objects: 4208, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 4208 (delta 1), reused 7 (delta 1), pack-reused 4196\u001b[K\n",
            "Receiving objects: 100% (4208/4208), 247.85 MiB | 34.35 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n",
            "Checking out files: 100% (4003/4003), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToBhn-XUPYHu",
        "outputId": "5625cc58-0057-4843-a77b-82e4aea5a610"
      },
      "source": [
        "!pip install data-path-utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting data-path-utils\n",
            "  Downloading https://files.pythonhosted.org/packages/ca/27/c84298d3d2726d9e13dfa9a6b636e0a044ba241bb0873f3c4ab101c34700/data_path_utils-0.8.1-py3-none-any.whl\n",
            "Installing collected packages: data-path-utils\n",
            "Successfully installed data-path-utils-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqE2FcvaPAR2"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "#from path_utils import list_images\n",
        "import argparse\n",
        "import os\n",
        "#from rgbhistogram import RGBHistogram\n",
        "import joblib\n",
        "# from xgboost import XGBClassifier\n",
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1iodpvYNrXW"
      },
      "source": [
        "def get_arguments():\n",
        "    # construct the argument parser and parse the arguments\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"-d\", \"--dataset\", type=str, default=\"animals\",\n",
        "                    help=\"path to directory containing the '3scenes' dataset\")\n",
        "    ap.add_argument(\"-m\", \"--model\", type=str, default=\"all\",\n",
        "                    help=\"type of python machine learning model to use\")\n",
        "    args = vars(ap.parse_args())\n",
        "\n",
        "    return args\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqtQuP6dQ4gt"
      },
      "source": [
        "validExts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
        "def get_image_features_and_labels(dataset_directory_name):\n",
        "    # grab all image paths in the input dataset directory, initialize our\n",
        "    # list of extracted features and corresponding labels\n",
        "    print(f\"[INFO] extracting image features from dataset: [{dataset_directory_name}]...\")\n",
        "    #imagePaths = list_images(dataset_directory_name)\n",
        "    for (rootDir, dirNames, filenames) in os.walk(dataset_directory_name):\n",
        "        # loop over the filenames in the current directory\n",
        "        for filename in filenames:\n",
        "            # if the contains string is not none and the filename does not contain\n",
        "            # the supplied string, then ignore the file\n",
        "            if contains is not None and filename.find(contains) == -1:\n",
        "                continue\n",
        "\n",
        "            # determine the file extension of the current file\n",
        "            ext = filename[filename.rfind(\".\"):].lower()\n",
        "\n",
        "            # check to see if the file is an image and should be processed\n",
        "            if validExts is None or ext.endswith(validExts):\n",
        "                # construct the path to the image and yield it\n",
        "                imagePath = os.path.join(rootDir, filename)\n",
        "                yield imagePath\n",
        "    feature_data = []\n",
        "    image_labels = []\n",
        "\n",
        "    # loop over our input images\n",
        "    for imagePath in imagePaths:\n",
        "        # load the input image from disk, compute color channel\n",
        "        # statistics, and then update our data list\n",
        "        # image = Image.open(imagePath)\n",
        "\n",
        "        # using color stats does help along with rgbhisto\n",
        "        # features = extract_color_stats(image)\n",
        "        # data.append(features)\n",
        "\n",
        "        # Depending upon the algorithm, using the histogram is helpful\n",
        "        # check out mlp with and without histogram\n",
        "        # check out random forest with and without\n",
        "        cv2_features = rgbHisto.get_features(imagePath)\n",
        "        feature_data.append(cv2_features)\n",
        "\n",
        "        # extract the class label from the file path and update the\n",
        "        # labels list\n",
        "        # label is the directory name where the images reside.  the name of the image file does not matter\n",
        "        label = imagePath.split(os.path.sep)[-2]\n",
        "        image_labels.append(label)\n",
        "\n",
        "    return feature_data, image_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXA60o8yQd1X"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  args= get_arguments()\n",
        "  dataset_dir_name = args['dataset']\n",
        "  X,y = get_image_features_and_labels(dataset_dir_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}